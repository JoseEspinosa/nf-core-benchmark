//
// This file holds several functions common to the multiple workflows in the nf-core/benchmark pipeline
//

class WorkflowCommons {

    //
    // Exit pipeline if incorrect --genome key provided
    //
    private static void genomeExistsError(params, log) {
        if (params.genomes && params.genome && !params.genomes.containsKey(params.genome)) {
            log.error "=============================================================================\n" +
                "  Genome '${params.genome}' not found in any config files provided to the pipeline.\n" +
                "  Currently, the available genome keys are:\n" +
                "  ${params.genomes.keySet().join(", ")}\n" +
                "==================================================================================="
            System.exit(1)
        }
    }

    //
    // Get workflow summary for MultiQC
    //
    public static String paramsSummaryMultiqc(workflow, summary) {
        String summary_section = ''
        for (group in summary.keySet()) {
            def group_params = summary.get(group)  // This gets the parameters of that particular group
            if (group_params) {
                summary_section += "    <p style=\"font-size:110%\"><b>$group</b></p>\n"
                summary_section += "    <dl class=\"dl-horizontal\">\n"
                for (param in group_params.keySet()) {
                    summary_section += "        <dt>$param</dt><dd><samp>${group_params.get(param) ?: '<span style=\"color:#999999;\">N/A</a>'}</samp></dd>\n"
                }
                summary_section += "    </dl>\n"
            }
        }

        String yaml_file_text  = "id: '${workflow.manifest.name.replace('/','-')}-summary'\n"
        yaml_file_text        += "description: ' - this information is collected when the pipeline is started.'\n"
        yaml_file_text        += "section_name: '${workflow.manifest.name} Workflow Summary'\n"
        yaml_file_text        += "section_href: 'https://github.com/${workflow.manifest.name}'\n"
        yaml_file_text        += "plot_type: 'html'\n"
        yaml_file_text        += "data: |\n"
        yaml_file_text        += "${summary_section}"
        return yaml_file_text
    }

    //
    // Function to check whether primer BED file has the correct suffixes as provided to the pipeline
    //
    public static void checkPrimerSuffixes(primer_bed_file, primer_left_suffix, primer_right_suffix, log) {
        def total = 0
        def left  = 0
        def right = 0
        primer_bed_file.eachLine { line ->
            total += 1
            def name = line.split('\t')[3]
            if (name.contains(primer_left_suffix)) {
                left += 1
            } else if (name.contains(primer_right_suffix)) (
                right += 1
            )
        }
        if (total != (left + right)) {
            log.warn "=============================================================================\n" +
                "  Please check the name field (column 4) in the file supplied via --primer_bed.\n\n" +
                "  All of the values in that column do not end with those supplied by:\n" +
                "      --primer_left_suffix : $primer_left_suffix\n" +
                "      --primer_right_suffix: $primer_right_suffix\n\n" +
                "  This information is required to collapse the primer intervals into amplicons\n" +
                "  for the coverage plots generated by the pipeline.\n" +
                "==================================================================================="
        }
    }

    //
    // Function to get lineage from Pangolin output file
    //
    public static String getPangolinLineage(pangolin_report) {
        def lineage = ''
        pangolin_report.eachLine { line ->
            lineage = line.split(',')[1]
        }
        return lineage
    }

    //
    // Function to get number of variants reported in BCFTools stats file
    //
    public static Integer getNumVariantsFromBCFToolsStats(bcftools_stats) {
        def num_vars = 0
        bcftools_stats.eachLine { line ->
            def matcher = line =~ /SN\s*0\s*number\sof\srecords:\s*([\d]+)/
            if (matcher) num_vars = matcher[0][1].toInteger()
        }
        return num_vars
    }

    //
    // Function to dynamically create a nextflow script to run the pipeline/benchmarker
    //
    public static String createModuleScript(params, workflow, log, workflow_type, module_name, workflow_name) {
        // TODO Check if exists
        // Delete if exists
        // Should be placed in the same folder as the original main.nf otherwise nextflow.config won't be read
        // Not even, this should be control from the main nf-core-benchmark
        // def module_name              = workflow_type == 'pipeline' ? params.pipeline : params.benchmarker
        // TODO do not check for name but for changed path like in nextflow!!!
        // TODO parametrize everything and don't assume any uppercase (this will be nf-core compliant but might not
        // useful for workflows outside nf-core) At least, rethink and document
        def md5                      = workflow_name.md5().toString().substring(0,6)
        def file_name                = "main_${md5}.nf"
        def module_dir               = new File("${params.benchmark_work}")
        def module_file              = new File("${params.benchmark_work}/" + file_name)
        def workflow_name_upper_case = workflow_name.toUpperCase()
        def workflow_type_upper_case = workflow_type.toUpperCase()
        def take_declaration         = workflow_type == 'benchmarker' ? 'take: data' : ''
        def run_declaration          = workflow_type == 'benchmarker' ? workflow_name_upper_case + '(data)' : workflow_name_upper_case + '()'
        def emit_declaration         = params.skip_emit && workflow_type == 'pipeline' ? "\"dummy\"" : "${workflow_name_upper_case}.out\n"

        if (!module_dir.exists()) {
            if (!module_dir.mkdirs()) {
                log.error "=============================================================================\n" +
                "  Failed to create include module directory: '${module_dir}'\n" +
                "  Make sure you have write permission.\n"
                "==================================================================================="
                System.exit(1)
            }
        }

        module_file.createNewFile()
        // ${workflow_type} = ${workflow_name_upper_case}.out
        module_file.text = """\
        #!/usr/bin/env nextflow

        nextflow.enable.dsl=2

        include { ${workflow_name_upper_case} } from "${workflow.projectDir}/${workflow_type}s/${module_name}/main.nf"

        workflow RUN_${workflow_type_upper_case} {
            ${take_declaration}

            main:
            ${run_declaration}

            emit:
            ${workflow_type} = ${emit_declaration}
        }

        workflow {
            RUN_${workflow_type_upper_case}()
        }
        """.stripIndent()

        while (!module_file.exists()) {
            sleep(1)
        }

        //execute permission
        "chmod +x $module_file".execute()

        return file_name
    }
}
